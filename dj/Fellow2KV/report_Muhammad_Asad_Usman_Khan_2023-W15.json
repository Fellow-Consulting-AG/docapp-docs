{
    "author": "Muhammad Asad Usman Khan",
    "week": "2023-W15",
    "total_commits": 24,
    "author_image": "https://avatars.githubusercontent.com/u/83513548?v=4",
    "commits": [
        {
            "sha": "491a42e8537bddd9353231bef5bf50937fa84faa",
            "message": "fd",
            "code_changes": "@@ -552,8 +552,8 @@ def get_field_confs(org_id: str, doc_type: str, sub_doc_type: str, field_name=No\n     if field_name:\n         query += f\" and f.field_name ilike '{field_name}'\"\n \n-    results = dbh.execute_scalar_query(db, query)\n-    results = [r._asdict() for r in results]\n+    results = dbh.execute_query(db, query)\n+    # results = [r._asdict() for r in results]\n     return {r[\"field_name\"].lower(): r for r in results}\n \n \n@@ -592,8 +592,8 @@ def get_table_column_confs(org_id: str, table_name: str, column_name=None):\n     if column_name and len(column_name.strip()) > 0:\n         query += f\"\"\" and dtc.column_name ILike '{column_name}'\"\"\"\n \n-    results = dbh.execute_scalar_query(db, query)\n-    results = [r._asdict() for r in results]\n+    results = dbh.execute_query(db, query)\n+    # results = [r._asdict() for r in results]\n     return {r[\"column_name\"]: r for r in results}\n \n "
        },
        {
            "sha": "b266336e02df867f44977adfbaf98be0fc64e9b7",
            "message": "fd",
            "code_changes": "@@ -362,8 +362,8 @@ def get_label_train_data(org_id):\n             and ccd.is_deleted = false;    \n     \"\"\"\n \n-    result = dbh.execute_scalar_query(db, sql)\n-    result = json.dumps([r._asdict() for r in result])\n+    result = dbh.execute_query(db, sql)\n+    result = json.dumps(result)\n     result = json.loads(result)\n \n     docs_dict = {r[\"doc_id\"]: r for r in result}\n@@ -386,8 +386,8 @@ def get_label_train_data(org_id):\n     for rec, val in docs_dict.items():\n         val[\"tag_ids\"] = []\n \n-    tags_result = dbh.execute_scalar_query(db, sql_tags)\n-    tags_result = json.dumps([r._asdict() for r in tags_result])\n+    tags_result = dbh.execute_query(db, sql_tags)\n+    tags_result = json.dumps(tags_result)\n     tags_result = json.loads(tags_result)\n \n     for rec in tags_result:"
        },
        {
            "sha": "bef11111d0d118e4c62b084d4da1c7f664f795eb",
            "message": "Merge pull request #877 from Fellow-Consulting-AG/dev\n\nfd",
            "code_changes": "@@ -9,28 +9,20 @@\n from helper.ai.ai_invoice import transform_fields_to_dict\n from helper.ai.ocr_process_util import generate_hard_regex_from_string\n from helper.extract_util import Extractor\n-from helper.plugin_export_util import (\n-    create_pending_tickets,\n-    create_rules_in_db,\n-    create_table_column_rules_in_db,\n-    create_table_rules_in_db,\n-    transform_to_rules,\n-    transform_to_table_rules,\n-    update_table_column_rule_patterns,\n-)\n+from helper.plugin_export_util import (create_pending_tickets,\n+                                       create_rules_in_db,\n+                                       create_table_column_rules_in_db,\n+                                       create_table_rules_in_db,\n+                                       transform_to_rules,\n+                                       transform_to_table_rules,\n+                                       update_table_column_rule_patterns)\n from helper.plugin_extraction_util import delete_table_rules_from_db\n from helper.rule_weight.rule_weight import update_weights\n from helper.table_extractors.table_draft_helper import get_table_draft\n from helper.tfidf_helper import handle_tfidf_v4_simple\n from logger import get_logger\n-from models import (\n-    FellowKVRegexes,\n-    FellowKVRule,\n-    FellowKVTableColumnRule,\n-    FellowKVTableRule,\n-    TableFormattingRules,\n-    TfidfDocs,\n-)\n+from models import (FellowKVRegexes, FellowKVRule, FellowKVTableColumnRule,\n+                    FellowKVTableRule, TableFormattingRules, TfidfDocs)\n \n logger = get_logger(\"fellowkv-export\")\n \n@@ -98,7 +90,7 @@ def post(self):\n             self: write your description\n         \"\"\"\n         user = multi_auth.current_user()\n-        logger.info(\"Request JSON:\" + json.dumps(request.json))\n+        # logger.info(\"Request JSON:\" + json.dumps(request.json))\n         request_data = request.json\n         docs = request_data.get(\"docs\", [])\n         return create_rules_in_db(docs, user)\n@@ -179,7 +171,7 @@ def post(self):\n             self: write your description\n         \"\"\"\n         user = multi_auth.current_user()\n-        logger.info(\"Request JSON:\" + json.dumps(request.json))\n+        # logger.info(\"Request JSON:\" + json.dumps(request.json))\n         export_data = json.loads(request.form.get(\"data\", \"[]\"))\n         docs = []\n         table_docs = []"
        },
        {
            "sha": "22d94ee37bd5ee1309fc305643a360f017bc74f9",
            "message": "fd",
            "code_changes": "@@ -9,28 +9,20 @@\n from helper.ai.ai_invoice import transform_fields_to_dict\n from helper.ai.ocr_process_util import generate_hard_regex_from_string\n from helper.extract_util import Extractor\n-from helper.plugin_export_util import (\n-    create_pending_tickets,\n-    create_rules_in_db,\n-    create_table_column_rules_in_db,\n-    create_table_rules_in_db,\n-    transform_to_rules,\n-    transform_to_table_rules,\n-    update_table_column_rule_patterns,\n-)\n+from helper.plugin_export_util import (create_pending_tickets,\n+                                       create_rules_in_db,\n+                                       create_table_column_rules_in_db,\n+                                       create_table_rules_in_db,\n+                                       transform_to_rules,\n+                                       transform_to_table_rules,\n+                                       update_table_column_rule_patterns)\n from helper.plugin_extraction_util import delete_table_rules_from_db\n from helper.rule_weight.rule_weight import update_weights\n from helper.table_extractors.table_draft_helper import get_table_draft\n from helper.tfidf_helper import handle_tfidf_v4_simple\n from logger import get_logger\n-from models import (\n-    FellowKVRegexes,\n-    FellowKVRule,\n-    FellowKVTableColumnRule,\n-    FellowKVTableRule,\n-    TableFormattingRules,\n-    TfidfDocs,\n-)\n+from models import (FellowKVRegexes, FellowKVRule, FellowKVTableColumnRule,\n+                    FellowKVTableRule, TableFormattingRules, TfidfDocs)\n \n logger = get_logger(\"fellowkv-export\")\n \n@@ -98,7 +90,7 @@ def post(self):\n             self: write your description\n         \"\"\"\n         user = multi_auth.current_user()\n-        logger.info(\"Request JSON:\" + json.dumps(request.json))\n+        # logger.info(\"Request JSON:\" + json.dumps(request.json))\n         request_data = request.json\n         docs = request_data.get(\"docs\", [])\n         return create_rules_in_db(docs, user)\n@@ -179,7 +171,7 @@ def post(self):\n             self: write your description\n         \"\"\"\n         user = multi_auth.current_user()\n-        logger.info(\"Request JSON:\" + json.dumps(request.json))\n+        # logger.info(\"Request JSON:\" + json.dumps(request.json))\n         export_data = json.loads(request.form.get(\"data\", \"[]\"))\n         docs = []\n         table_docs = []"
        },
        {
            "sha": "a9904d019b7406111a95aa243e9c19704cca12dd",
            "message": "Merge pull request #875 from Fellow-Consulting-AG/dev\n\nfd",
            "code_changes": "@@ -23,10 +23,14 @@ def execute_scalar_query(db, query):\n         pass\n     with db.engine.connect() as conn:\n         try:\n-            return conn.execute(text(query))\n+            result = conn.execute(text(query))\n+            conn.commit()\n+            return result\n         except:\n             pass\n-        return conn.execute(query)\n+        result = conn.execute(query)\n+        conn.commit()\n+        return result\n \n \n def get_single_result(db, query):"
        },
        {
            "sha": "cab57d1447f8690c22f15c214c59bc24e14da570",
            "message": "fd",
            "code_changes": "@@ -23,10 +23,14 @@ def execute_scalar_query(db, query):\n         pass\n     with db.engine.connect() as conn:\n         try:\n-            return conn.execute(text(query))\n+            result = conn.execute(text(query))\n+            conn.commit()\n+            return result\n         except:\n             pass\n-        return conn.execute(query)\n+        result = conn.execute(query)\n+        conn.commit()\n+        return result\n \n \n def get_single_result(db, query):"
        },
        {
            "sha": "ee418aaa80dd50623adfde6807bce072bbd98fd9",
            "message": "Merge branch 'sandbox' into stage",
            "code_changes": ""
        },
        {
            "sha": "25ec1a4798e26a0ec71370a8dd3ab6e0ae88572e",
            "message": "Merge pull request #873 from Fellow-Consulting-AG/dev\n\nfd",
            "code_changes": "@@ -1 +1 @@\n-2.0.560.1\n\\ No newline at end of file\n+2.0.561\n\\ No newline at end of file"
        },
        {
            "sha": "bab31c50317bc4a922e263a3df50ebd7d60de705",
            "message": "Merge branch 'stage' into dev",
            "code_changes": ""
        },
        {
            "sha": "b957f9db5bf319dfd359daa1e7a87ed0dcd5b3c2",
            "message": "Merge pull request #872 from Fellow-Consulting-AG/stage\n\nStage",
            "code_changes": "@@ -6,6 +6,9 @@\n import time\n import warnings\n \n+from sqlalchemy import create_engine\n+from sqlalchemy import text as sql_text\n+\n from helper.ai.ocr_process_util import populate_custom_lines\n \n warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n@@ -89,8 +92,7 @@ def get_all_similar_docs_above_threshold(source_record_id, threshold, org_id):\n                     created_on DESC\"\"\"\n \n     tfidf_query = tfidf_query.replace(\"\\n\", \"\")\n-\n-    df1 = pd.read_sql(sql=tfidf_query, con=os.getenv(\"SQLALCHEMY_DATABASE_AURI\"))\n+    df1 = get_dataframe_from_query(os.getenv(\"SQLALCHEMY_DATABASE_AURI\"), tfidf_query)\n \n     # getting text and cleaning it\n     df1[\"clean_text\"] = df1[\"doc_text\"].pipe(hero.clean)\n@@ -166,9 +168,7 @@ def get_similar_documents(threshold, record: TfidfDocs):  # , auto_types=[]\n \n     tfidf_query = tfidf_query.replace(\"\\n\", \"\")\n \n-    df1 = pd.read_sql(\n-        sql=tfidf_query, con=os.getenv(\"SQLALCHEMY_DATABASE_AURI\")\n-    )  # , index_col='id')\n+    df1 = get_dataframe_from_query(os.getenv(\"SQLALCHEMY_DATABASE_AURI\"), tfidf_query)  # , index_col='id')\n     logger.info(f\"Total TFIDF records found = {len(df1)}\")\n     # getting text and cleaning it\n     df1[\"clean_text\"] = df1[\"doc_text\"].pipe(hero.clean)\n@@ -279,9 +279,7 @@ def get_similar_documents_simple(document, threshold, source_record_id):\n         + where_clause\n         + \") order by sort_order asc, created_on desc\"\n     )\n-    df1 = pd.read_sql(\n-        sql=tfidf_query, con=os.getenv(\"SQLALCHEMY_DATABASE_AURI\")\n-    )  # , index_col='id')\n+    df1 = get_dataframe_from_query(os.getenv(\"SQLALCHEMY_DATABASE_AURI\"), tfidf_query)  # , index_col='id')\n \n     # getting text and cleaning it\n     df1[\"clean_text\"] = df1[\"doc_text\"].pipe(hero.clean)\n@@ -594,3 +592,10 @@ def handle_tfidf_v4_simple(document):\n \n     # document[\"filter_values\"] = [document[\"tfidf_id\"]]\n     return document\n+\n+def get_dataframe_from_query(connection_string, query):\n+    connection = create_engine(connection_string)\n+    # df1 = pd.read_sql(sql=tfidf_query, con=os.getenv(\"SQLALCHEMY_DATABASE_AURI\"))\n+    df = pd.read_sql_query(con=connection.connect(), \n+                                  sql=sql_text(query))\n+    return df\n\\ No newline at end of file"
        },
        {
            "sha": "e6c2cc3a3abe24f8f6cefc0121828f22e4dfbb0f",
            "message": "Merge pull request #871 from Fellow-Consulting-AG/dev\n\nfd",
            "code_changes": "@@ -6,6 +6,9 @@\n import time\n import warnings\n \n+from sqlalchemy import create_engine\n+from sqlalchemy import text as sql_text\n+\n from helper.ai.ocr_process_util import populate_custom_lines\n \n warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n@@ -89,8 +92,7 @@ def get_all_similar_docs_above_threshold(source_record_id, threshold, org_id):\n                     created_on DESC\"\"\"\n \n     tfidf_query = tfidf_query.replace(\"\\n\", \"\")\n-\n-    df1 = pd.read_sql(sql=tfidf_query, con=os.getenv(\"SQLALCHEMY_DATABASE_AURI\"))\n+    df1 = get_dataframe_from_query(os.getenv(\"SQLALCHEMY_DATABASE_AURI\"), tfidf_query)\n \n     # getting text and cleaning it\n     df1[\"clean_text\"] = df1[\"doc_text\"].pipe(hero.clean)\n@@ -166,9 +168,7 @@ def get_similar_documents(threshold, record: TfidfDocs):  # , auto_types=[]\n \n     tfidf_query = tfidf_query.replace(\"\\n\", \"\")\n \n-    df1 = pd.read_sql(\n-        sql=tfidf_query, con=os.getenv(\"SQLALCHEMY_DATABASE_AURI\")\n-    )  # , index_col='id')\n+    df1 = get_dataframe_from_query(os.getenv(\"SQLALCHEMY_DATABASE_AURI\"), tfidf_query)  # , index_col='id')\n     logger.info(f\"Total TFIDF records found = {len(df1)}\")\n     # getting text and cleaning it\n     df1[\"clean_text\"] = df1[\"doc_text\"].pipe(hero.clean)\n@@ -279,9 +279,7 @@ def get_similar_documents_simple(document, threshold, source_record_id):\n         + where_clause\n         + \") order by sort_order asc, created_on desc\"\n     )\n-    df1 = pd.read_sql(\n-        sql=tfidf_query, con=os.getenv(\"SQLALCHEMY_DATABASE_AURI\")\n-    )  # , index_col='id')\n+    df1 = get_dataframe_from_query(os.getenv(\"SQLALCHEMY_DATABASE_AURI\"), tfidf_query)  # , index_col='id')\n \n     # getting text and cleaning it\n     df1[\"clean_text\"] = df1[\"doc_text\"].pipe(hero.clean)\n@@ -594,3 +592,10 @@ def handle_tfidf_v4_simple(document):\n \n     # document[\"filter_values\"] = [document[\"tfidf_id\"]]\n     return document\n+\n+def get_dataframe_from_query(connection_string, query):\n+    connection = create_engine(connection_string)\n+    # df1 = pd.read_sql(sql=tfidf_query, con=os.getenv(\"SQLALCHEMY_DATABASE_AURI\"))\n+    df = pd.read_sql_query(con=connection.connect(), \n+                                  sql=sql_text(query))\n+    return df\n\\ No newline at end of file"
        },
        {
            "sha": "a626c0537cabade12061e1632d7dfaab0476e0f8",
            "message": "fd",
            "code_changes": "@@ -6,6 +6,9 @@\n import time\n import warnings\n \n+from sqlalchemy import create_engine\n+from sqlalchemy import text as sql_text\n+\n from helper.ai.ocr_process_util import populate_custom_lines\n \n warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n@@ -89,8 +92,7 @@ def get_all_similar_docs_above_threshold(source_record_id, threshold, org_id):\n                     created_on DESC\"\"\"\n \n     tfidf_query = tfidf_query.replace(\"\\n\", \"\")\n-\n-    df1 = pd.read_sql(sql=tfidf_query, con=os.getenv(\"SQLALCHEMY_DATABASE_AURI\"))\n+    df1 = get_dataframe_from_query(os.getenv(\"SQLALCHEMY_DATABASE_AURI\"), tfidf_query)\n \n     # getting text and cleaning it\n     df1[\"clean_text\"] = df1[\"doc_text\"].pipe(hero.clean)\n@@ -166,9 +168,7 @@ def get_similar_documents(threshold, record: TfidfDocs):  # , auto_types=[]\n \n     tfidf_query = tfidf_query.replace(\"\\n\", \"\")\n \n-    df1 = pd.read_sql(\n-        sql=tfidf_query, con=os.getenv(\"SQLALCHEMY_DATABASE_AURI\")\n-    )  # , index_col='id')\n+    df1 = get_dataframe_from_query(os.getenv(\"SQLALCHEMY_DATABASE_AURI\"), tfidf_query)  # , index_col='id')\n     logger.info(f\"Total TFIDF records found = {len(df1)}\")\n     # getting text and cleaning it\n     df1[\"clean_text\"] = df1[\"doc_text\"].pipe(hero.clean)\n@@ -279,9 +279,7 @@ def get_similar_documents_simple(document, threshold, source_record_id):\n         + where_clause\n         + \") order by sort_order asc, created_on desc\"\n     )\n-    df1 = pd.read_sql(\n-        sql=tfidf_query, con=os.getenv(\"SQLALCHEMY_DATABASE_AURI\")\n-    )  # , index_col='id')\n+    df1 = get_dataframe_from_query(os.getenv(\"SQLALCHEMY_DATABASE_AURI\"), tfidf_query)  # , index_col='id')\n \n     # getting text and cleaning it\n     df1[\"clean_text\"] = df1[\"doc_text\"].pipe(hero.clean)\n@@ -594,3 +592,10 @@ def handle_tfidf_v4_simple(document):\n \n     # document[\"filter_values\"] = [document[\"tfidf_id\"]]\n     return document\n+\n+def get_dataframe_from_query(connection_string, query):\n+    connection = create_engine(connection_string)\n+    # df1 = pd.read_sql(sql=tfidf_query, con=os.getenv(\"SQLALCHEMY_DATABASE_AURI\"))\n+    df = pd.read_sql_query(con=connection.connect(), \n+                                  sql=sql_text(query))\n+    return df\n\\ No newline at end of file"
        },
        {
            "sha": "9d4cfedbf8e9b6d0304c021184a67abc48a9bd39",
            "message": "Merge pull request #870 from Fellow-Consulting-AG/stage\n\nStage",
            "code_changes": ""
        },
        {
            "sha": "5de0e8f6a212e85dbab9a4687ac3d42fbc506d0c",
            "message": "Merge pull request #869 from Fellow-Consulting-AG/dev\n\nfd",
            "code_changes": "@@ -7,7 +7,11 @@ def execute_query(db, query):\n     except:\n         pass\n     with db.engine.connect() as conn:\n-        results = conn.execute(text(query))\n+        try:\n+            results = conn.execute(text(query))\n+        except:\n+            results = conn.execute(query)\n+\n         results_list = [r._asdict() for r in results]\n         return results_list\n \n@@ -18,7 +22,11 @@ def execute_scalar_query(db, query):\n     except:\n         pass\n     with db.engine.connect() as conn:\n-        return conn.execute(text(query))\n+        try:\n+            return conn.execute(text(query))\n+        except:\n+            pass\n+        return conn.execute(query)\n \n \n def get_single_result(db, query):"
        },
        {
            "sha": "513b525351ad0e5a22ee0f43f3901d0e7c6ba4ed",
            "message": "fd",
            "code_changes": "@@ -553,7 +553,8 @@ def get_field_confs(org_id: str, doc_type: str, sub_doc_type: str, field_name=No\n         query += f\" and f.field_name ilike '{field_name}'\"\n \n     results = dbh.execute_scalar_query(db, query)\n-    return {r[\"field_name\"].lower(): r._asdict() for r in results}\n+    results = [r._asdict() for r in results]\n+    return {r[\"field_name\"].lower(): r for r in results}\n \n \n def get_table_layout(db, table_name, org_id):\n@@ -592,7 +593,8 @@ def get_table_column_confs(org_id: str, table_name: str, column_name=None):\n         query += f\"\"\" and dtc.column_name ILike '{column_name}'\"\"\"\n \n     results = dbh.execute_scalar_query(db, query)\n-    return {r[\"column_name\"]: r._asdict() for r in results}\n+    results = [r._asdict() for r in results]\n+    return {r[\"column_name\"]: r for r in results}\n \n \n ######"
        },
        {
            "sha": "0aa08ad62a6b0c0a5e7a2257eb498a7c59b9492b",
            "message": "fd",
            "code_changes": "@@ -39,7 +39,7 @@ def get(self):\n         # common.get_models_list.cache_clear()\n         ttl = common.get_ttl_hash()\n         models = common.get_models_list(org_id, ttl)\n-        return json.loads(json.dumps([r._asdict() for r in models], default=alchemyencoder))\n+        return json.loads(json.dumps([dict(r) for r in models], default=alchemyencoder))\n \n \n aiparser = api.parser()"
        },
        {
            "sha": "54502f5d8293e2f0294597c8a93dbac3dadb5633",
            "message": "fd",
            "code_changes": "@@ -93,7 +93,7 @@ requests-oauthlib==1.3\n rsa==4.8\n s3transfer==0.6\n scikit-image==0.19.2\n-scikit-learn==1.2.2\n+scikit-learn==1.0.2\n scipy==1.10.1\n Shapely==2.0.1\n six==1.16"
        },
        {
            "sha": "e8c2b72efa6e2e0f2e4f3c85af677a0a63ed7fc2",
            "message": "_asdict",
            "code_changes": "@@ -363,7 +363,7 @@ def get_label_train_data(org_id):\n     \"\"\"\n \n     result = dbh.execute_scalar_query(db, sql)\n-    result = json.dumps([dict(r) for r in result])\n+    result = json.dumps([r._asdict() for r in result])\n     result = json.loads(result)\n \n     docs_dict = {r[\"doc_id\"]: r for r in result}\n@@ -387,7 +387,7 @@ def get_label_train_data(org_id):\n         val[\"tag_ids\"] = []\n \n     tags_result = dbh.execute_scalar_query(db, sql_tags)\n-    tags_result = json.dumps([dict(r) for r in tags_result])\n+    tags_result = json.dumps([r._asdict() for r in tags_result])\n     tags_result = json.loads(tags_result)\n \n     for rec in tags_result:"
        },
        {
            "sha": "a322798fefac5edfb2b8b77cac21a3f53f2bad84",
            "message": "fd",
            "code_changes": "@@ -29,7 +29,7 @@ Flask-RESTful==0.3.9\n flask-restx==1.1.0\n Flask-SQLAlchemy==3.0.2\n fonttools==4.31.2\n-gensim==3.6.0\n+gensim==3.8.3\n gevent==22.10.2\n google-auth==2.16\n greenlet==2.0.2\n@@ -92,9 +92,9 @@ requests==2.28.2\n requests-oauthlib==1.3\n rsa==4.8\n s3transfer==0.6\n-scikit-image==0.20.0\n+scikit-image==0.19.2\n scikit-learn==1.2.2\n-scipy==1.8.1\n+scipy==1.10.1\n Shapely==2.0.1\n six==1.16\n smart-open==5.2"
        },
        {
            "sha": "cfab6fc667b0e96f8555cb0890a05ad29991265b",
            "message": "fd",
            "code_changes": "@@ -94,7 +94,7 @@ rsa==4.8\n s3transfer==0.6\n scikit-image==0.20.0\n scikit-learn==1.2.2\n-scipy==1.10.1\n+scipy==1.8.1\n Shapely==2.0.1\n six==1.16\n smart-open==5.2"
        },
        {
            "sha": "581fecb4b24a80f2b1b960e0c93a017023b02c35",
            "message": "fd",
            "code_changes": "@@ -94,7 +94,7 @@ rsa==4.8\n s3transfer==0.6\n scikit-image==0.20.0\n scikit-learn==1.2.2\n-scipy==1.8.1\n+scipy==1.10.1\n Shapely==2.0.1\n six==1.16\n smart-open==5.2"
        },
        {
            "sha": "17ea2e0fe935b1810ccd41cff81668b8c5281cd3",
            "message": "fd",
            "code_changes": "@@ -1,168 +1,127 @@\n-aiohttp==3.8.4\n-aiosignal==1.3.1\n alembic==1.10.3\n-aniso8601==9.0.0\n-async-timeout==4.0.2\n-attrs==21.4.0\n-Babel==2.9.0\n+aniso8601==9.0\n+attrs==21.4\n+Babel==2.9\n blis==0.7.9\n boto3==1.26.108\n botocore==1.29.108\n-cachetools==4.2.0\n-camelot-py==0.11.0\n-catalogue==1.0.0\n+cachetools==4.2\n+camelot-py==0.11\n+catalogue==1.0\n certifi==2022.12.7\n-cffi==1.15.0\n-chardet==4.0.0\n+cffi==1.15\n+chardet==4.0\n charset-normalizer==3.1.0\n-ci-info==0.3.0\n click==8.1.3\n-configobj==5.0.8\n-configparser==5.3.0\n-contourpy==1.0.7\n cryptography==40.0.1\n-cycler==0.11.0\n+cycler==0.11\n cymem==2.0.7\n-decorator==5.1.0\n-deprecation==2.1.0\n+decorator==5.1\n deskew==1.4.3\n en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n et-xmlfile==1.1.0\n-etelemetry==0.3.0\n-exceptiongroup==1.1.1\n-filelock==3.11.0\n Flask==2.2.3\n Flask-Dance==6.2.0\n Flask-HTTPAuth==4.7.0\n-flask-marshmallow==0.15.0\n-Flask-Migrate==3.0.0\n+flask-marshmallow==0.15\n+Flask-Migrate==3.0\n Flask-RESTful==0.3.9\n flask-restx==1.1.0\n Flask-SQLAlchemy==3.0.2\n fonttools==4.31.2\n-frozenlist==1.3.3\n-future==0.18.3\n gensim==3.6.0\n gevent==22.10.2\n-google-auth==2.16.0\n+google-auth==2.16\n greenlet==2.0.2\n-gunicorn==20.1.0\n-hocr-tools==1.1.0\n-httplib2==0.22.0\n+gunicorn==20.1\n+hocr-tools==1.1\n idna==3.3\n-imageio==2.16.0\n-img2pdf==0.4.0\n-importlib-metadata==6.1.0\n-importlib-resources==5.6.0\n-iniconfig==2.0.0\n-isodate==0.6.1\n+imageio==2.16\n+img2pdf==0.4\n+importlib-resources==5.6\n itsdangerous==2.1.2\n Jinja2==3.1.2\n-jmespath==1.0.0\n-joblib==1.2.0\n-jsonschema==4.4.0\n+jmespath==1.0\n+joblib==1.2\n+jsonschema==4.4\n jwt==1.3.1\n-kiwisolver==1.4.0\n-langdetect==1.0.0\n-lazy_loader==0.2\n-logtail==1.0.1\n+kiwisolver==1.4\n+langdetect==1.0\n logtail-python==0.2.3\n-looseversion==1.1.2\n-lxml==4.8.0\n+lxml==4.8\n Mako==1.2.0\n MarkupSafe==2.1.1\n marshmallow==3.12.2\n-marshmallow-sqlalchemy==0.29.0\n-matplotlib==3.5.0\n-msgpack==1.0.5\n-multidict==6.0.4\n-murmurhash==1.0.0\n+marshmallow-sqlalchemy==0.29\n+matplotlib==3.5\n+murmurhash==1.0\n networkx==3.1\n-nibabel==5.1.0\n-nipype==1.8.6\n nltk==3.7\n numpy==1.24.2\n oauthlib==3.1.1\n-openai==0.27.4\n opencv-python==4.7.0.68\n openpyxl==3.1.2\n packaging==21.3\n pandas==1.5.3\n-pathlib==1.0.1\n-pbr==5.6.0\n-pdf2image==1.16.0\n-pdfminer.six==20221105\n-pdfrw==0.4\n-pikepdf==5.1.0\n-Pillow==9.1.0\n-plac==1.1.0\n-plotly==5.7.0\n-pluggy==1.0.0\n+pbr==5.6\n+pdf2image==1.16\n+pdfminer.six==20220319\n+pikepdf==5.1\n+Pillow==9.1\n+plac==1.1\n+plotly==5.7\n preshed==3.0.8\n-protobuf==4.22.1\n-prov==2.0.0\n psycopg2-binary==2.9.6\n-py==1.11.0\n pyasn1==0.4.8\n pyasn1-modules==0.2.8\n pycparser==2.21\n-pycryptodome==3.17\n-pydot==1.4.2\n-PyJWT==2.6.0\n PyMuPDF==1.21.1\n-pyparsing==3.0.0\n-pypdf==3.7.0\n-PyPDF2==2.12.0\n-pyrsistent==0.18.0\n-pytesseract==0.3.0\n-pytest==7.1.0\n+pyparsing==3.0\n+PyPDF2==2.12\n+pyrsistent==0.18\n+pytesseract==0.3\n python-dateutil==2.8.2\n-python-dotenv==0.18.0\n+python-dotenv==0.18\n python-editor==1.0\n pytz==2022.1\n-PyWavelets==1.3.0\n-pyxnat==1.5\n+PyWavelets==1.3\n PyYAML==6.0\n-rdflib==6.3.2\n regex==2023.3.23\n reportlab==3.6.9\n requests==2.28.2\n-requests-oauthlib==1.3.0\n+requests-oauthlib==1.3\n rsa==4.8\n-s3transfer==0.6.0\n+s3transfer==0.6\n scikit-image==0.20.0\n scikit-learn==1.2.2\n scipy==1.8.1\n-setuptools-scm==7.1.0\n-shapely==2.0.1\n-simplejson==3.19.1\n-six==1.16.0\n-smart-open==5.2.0\n+Shapely==2.0.1\n+six==1.16\n+smart-open==5.2\n spacy==2.3.7\n SQLAlchemy==2.0.9\n-sqlalchemy-migrate==0.13.0\n+sqlalchemy-migrate==0.13\n SQLAlchemy-Utils==0.40.0\n sqlparse==0.4.3\n srsly==1.0.2\n tabulate==0.9.0\n Tempita==0.5.2\n-tenacity==8.0.0\n-texthero==1.1.0\n+tenacity==8.0\n+texthero==1.1\n thinc==7.4.5\n-threadpoolctl==3.1.0\n+threadpoolctl==3.1\n tifffile==2023.3.21\n-tomli==2.0.1\n-tqdm==4.64.0\n-traits==6.3.2\n-typing_extensions==4.5.0\n-tzdata==2023.3\n-Unidecode==1.3.0\n-urllib3==1.26.0\n-URLObject==2.4.0\n-wasabi==0.9.0\n+tqdm==4.64\n+Unidecode==1.3\n+urllib3==1.26\n+URLObject==2.4\n+wasabi==0.9\n Werkzeug==2.2.3\n wordcloud==1.8.2.2\n-yarl==1.8.2\n-zipp==3.8.0\n-zope.event==4.5.0\n-zope.interface==5.4.0\n+zipp==3.8\n+zope.event==4.5\n+zope.interface==5.4\n+pytest==7.1\n+pdfrw==0.4\n+wheel==0.40\n+openai==0.27.4\n\\ No newline at end of file"
        },
        {
            "sha": "2c3f43de07bfd0735791fad8937e7eed090407ee",
            "message": "fd",
            "code_changes": "@@ -10,7 +10,7 @@ boto3==1.26.108\n botocore==1.29.108\n cachetools==4.2.0\n camelot-py==0.11.0\n-catalogue==1.0.0a\n+catalogue==1.0.0\n certifi==2022.12.7\n cffi==1.15.0\n chardet==4.0.0"
        },
        {
            "sha": "8be1ebb9932cdc18ae3c6040b8ca108d1dc5bbf4",
            "message": "fd",
            "code_changes": "@@ -1,127 +1,168 @@\n+aiohttp==3.8.4\n+aiosignal==1.3.1\n alembic==1.10.3\n-aniso8601==9.0\n-attrs==21.4\n-Babel==2.9\n+aniso8601==9.0.0\n+async-timeout==4.0.2\n+attrs==21.4.0\n+Babel==2.9.0\n blis==0.7.9\n boto3==1.26.108\n botocore==1.29.108\n-cachetools==4.2\n-camelot-py==0.11\n-catalogue==1.0\n+cachetools==4.2.0\n+camelot-py==0.11.0\n+catalogue==1.0.0a\n certifi==2022.12.7\n-cffi==1.15\n-chardet==4.0\n+cffi==1.15.0\n+chardet==4.0.0\n charset-normalizer==3.1.0\n+ci-info==0.3.0\n click==8.1.3\n+configobj==5.0.8\n+configparser==5.3.0\n+contourpy==1.0.7\n cryptography==40.0.1\n-cycler==0.11\n+cycler==0.11.0\n cymem==2.0.7\n-decorator==5.1\n+decorator==5.1.0\n+deprecation==2.1.0\n deskew==1.4.3\n en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz\n et-xmlfile==1.1.0\n+etelemetry==0.3.0\n+exceptiongroup==1.1.1\n+filelock==3.11.0\n Flask==2.2.3\n Flask-Dance==6.2.0\n Flask-HTTPAuth==4.7.0\n-flask-marshmallow==0.15\n-Flask-Migrate==3.0\n+flask-marshmallow==0.15.0\n+Flask-Migrate==3.0.0\n Flask-RESTful==0.3.9\n flask-restx==1.1.0\n Flask-SQLAlchemy==3.0.2\n fonttools==4.31.2\n+frozenlist==1.3.3\n+future==0.18.3\n gensim==3.6.0\n gevent==22.10.2\n-google-auth==2.16\n+google-auth==2.16.0\n greenlet==2.0.2\n-gunicorn==20.1\n-hocr-tools==1.1\n+gunicorn==20.1.0\n+hocr-tools==1.1.0\n+httplib2==0.22.0\n idna==3.3\n-imageio==2.16\n-img2pdf==0.4\n-importlib-resources==5.6\n+imageio==2.16.0\n+img2pdf==0.4.0\n+importlib-metadata==6.1.0\n+importlib-resources==5.6.0\n+iniconfig==2.0.0\n+isodate==0.6.1\n itsdangerous==2.1.2\n Jinja2==3.1.2\n-jmespath==1.0\n-joblib==1.2\n-jsonschema==4.4\n+jmespath==1.0.0\n+joblib==1.2.0\n+jsonschema==4.4.0\n jwt==1.3.1\n-kiwisolver==1.4\n-langdetect==1.0\n+kiwisolver==1.4.0\n+langdetect==1.0.0\n+lazy_loader==0.2\n+logtail==1.0.1\n logtail-python==0.2.3\n-lxml==4.8\n+looseversion==1.1.2\n+lxml==4.8.0\n Mako==1.2.0\n MarkupSafe==2.1.1\n marshmallow==3.12.2\n-marshmallow-sqlalchemy==0.29\n-matplotlib==3.5\n-murmurhash==1.0\n+marshmallow-sqlalchemy==0.29.0\n+matplotlib==3.5.0\n+msgpack==1.0.5\n+multidict==6.0.4\n+murmurhash==1.0.0\n networkx==3.1\n+nibabel==5.1.0\n+nipype==1.8.6\n nltk==3.7\n numpy==1.24.2\n oauthlib==3.1.1\n+openai==0.27.4\n opencv-python==4.7.0.68\n openpyxl==3.1.2\n packaging==21.3\n pandas==1.5.3\n-pbr==5.6\n-pdf2image==1.16\n-pdfminer.six==20220319\n-pikepdf==5.1\n-Pillow==9.1\n-plac==1.1\n-plotly==5.7\n+pathlib==1.0.1\n+pbr==5.6.0\n+pdf2image==1.16.0\n+pdfminer.six==20221105\n+pdfrw==0.4\n+pikepdf==5.1.0\n+Pillow==9.1.0\n+plac==1.1.0\n+plotly==5.7.0\n+pluggy==1.0.0\n preshed==3.0.8\n+protobuf==4.22.1\n+prov==2.0.0\n psycopg2-binary==2.9.6\n+py==1.11.0\n pyasn1==0.4.8\n pyasn1-modules==0.2.8\n pycparser==2.21\n+pycryptodome==3.17\n+pydot==1.4.2\n+PyJWT==2.6.0\n PyMuPDF==1.21.1\n-pyparsing==3.0\n-PyPDF2==2.12\n-pyrsistent==0.18\n-pytesseract==0.3\n+pyparsing==3.0.0\n+pypdf==3.7.0\n+PyPDF2==2.12.0\n+pyrsistent==0.18.0\n+pytesseract==0.3.0\n+pytest==7.1.0\n python-dateutil==2.8.2\n-python-dotenv==0.18\n+python-dotenv==0.18.0\n python-editor==1.0\n pytz==2022.1\n-PyWavelets==1.3\n+PyWavelets==1.3.0\n+pyxnat==1.5\n PyYAML==6.0\n+rdflib==6.3.2\n regex==2023.3.23\n reportlab==3.6.9\n requests==2.28.2\n-requests-oauthlib==1.3\n+requests-oauthlib==1.3.0\n rsa==4.8\n-s3transfer==0.6\n+s3transfer==0.6.0\n scikit-image==0.20.0\n scikit-learn==1.2.2\n scipy==1.8.1\n-Shapely==2.0.1\n-six==1.16\n-smart-open==5.2\n+setuptools-scm==7.1.0\n+shapely==2.0.1\n+simplejson==3.19.1\n+six==1.16.0\n+smart-open==5.2.0\n spacy==2.3.7\n SQLAlchemy==2.0.9\n-sqlalchemy-migrate==0.13\n+sqlalchemy-migrate==0.13.0\n SQLAlchemy-Utils==0.40.0\n sqlparse==0.4.3\n srsly==1.0.2\n tabulate==0.9.0\n Tempita==0.5.2\n-tenacity==8.0\n-texthero==1.1\n+tenacity==8.0.0\n+texthero==1.1.0\n thinc==7.4.5\n-threadpoolctl==3.1\n+threadpoolctl==3.1.0\n tifffile==2023.3.21\n-tqdm==4.64\n-Unidecode==1.3\n-urllib3==1.26\n-URLObject==2.4\n-wasabi==0.9\n+tomli==2.0.1\n+tqdm==4.64.0\n+traits==6.3.2\n+typing_extensions==4.5.0\n+tzdata==2023.3\n+Unidecode==1.3.0\n+urllib3==1.26.0\n+URLObject==2.4.0\n+wasabi==0.9.0\n Werkzeug==2.2.3\n wordcloud==1.8.2.2\n-zipp==3.8\n-zope.event==4.5\n-zope.interface==5.4\n-pytest==7.1\n-pdfrw==0.4\n-wheel==0.40\n-#openai\n\\ No newline at end of file\n+yarl==1.8.2\n+zipp==3.8.0\n+zope.event==4.5.0\n+zope.interface==5.4.0"
        }
    ]
}